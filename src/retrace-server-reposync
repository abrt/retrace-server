#!/usr/bin/python3
import argparse
import errno
import os
import logging
import grp
import pwd
import shutil
import sys
import tempfile
from pathlib import Path

import rpm
import dnf

from functools import cmp_to_key
from pathlib import Path
from subprocess import run, DEVNULL, PIPE

from retrace.retrace import (get_canon_arch,
                             log_debug,
                             log_error,
                             log_info,
                             log_warn)

from retrace.config import Config
from retrace.plugins import Plugins
from retrace.util import lock, unlock, parse_rpm_name

sys.path.insert(0, "/usr/share/retrace-server")


CONFIG = Config()
plugins = Plugins()

TARGET_USER = "retrace"
TARGET_GROUP = CONFIG["AuthGroup"]

BUFSIZE = 1 << 22 # 4 MB


def sync_using_dnf(targetid, repourl, globaldnfcfg="", localdnfcfg=""):
    dnftmp = tempfile.NamedTemporaryFile(mode="w", delete=False,
                                         prefix="repo", suffix=".conf")
    dnftmp.write(globaldnfcfg)
    dnftmp.write("[%s]\n" % targetid)
    dnftmp.write("name=%s\n" % targetid)
    dnftmp.write("baseurl=%s\n" % repourl)
    dnftmp.write(localdnfcfg)
    dnftmp.close()

    with Path(dnftmp.name).open("r") as f:
        log_debug("Using dnf config from %s\n%s" % (dnftmp.name, f.read()))

    pkgdir = Path(CONFIG["RepoDir"], targetid, "Packages")
    tmpdir = Path(CONFIG["RepoDir"], "temp", targetid)
    if not tmpdir.is_dir():
        tmpdir.mkdir(parents=True)

    try:
        with Path(CONFIG["LogDir"], "reposync_dnf.log").open(mode="a") as dnflog:
            old_stderr = sys.stderr
            sys.stderr = dnflog

            # BEGIN DNF
            dnfbase = dnf.Base()
            dnfbase.conf.read(filename=dnftmp.name)
            if not dnfbase.conf.cachedir:
                sys.stderr = old_stderr
                log_error("Unable to initialize DNF cache")
                return -1

            cachedir = Path(dnfbase.conf.cachedir, targetid)
            if cachedir.is_dir():
                shutil.rmtree(cachedir)
            dnfbase.read_all_repos()

            for repo in dnfbase.repos.iter_enabled():
                repo.disable()

            dnfbase.repos[targetid].enable()

            try:
                # Fill the sack with repository packages
                dnfbase.fill_sack(load_system_repo=False)
            except Exception as ex:
                sys.stderr = old_stderr
                log_error(str(ex))
                return -1

            packages = list(dnfbase.sack.query())
            retcode = 0
            download = []

            for package in packages:
                rpmname = Path(package.location).name
                pkgpath = pkgdir / rpmname
                if not pkgpath.is_file() or pkgpath.stat().st_size != package.size:
                    log_info("%s will be downloaded" % rpmname)
                    download.append(package)
                else:
                    log_debug("%s is already downloaded, skipping" % rpmname)





            errors = dnfbase.download_packages(download)
            for error in errors:
                old_stderr.write("An error occured during download\n%s: %s" % (error, errors[error]))

            for package in download:
                downloadpath = Path(package.localPkg())
                pkgname = downloadpath.name
                targetpath = pkgdir / pkgname

                if not downloadpath.is_file():
                    # error message should be listed in errors
                    continue

                if targetpath.is_file():
                    targetpath.unlink()

                try:
                    downloadpath.rename(targetpath)
                except OSError as ex:
                    if ex.errno != errno.EXDEV:
                        raise

                    shutil.copy2(downloadpath, targetpath)
                    downloadpath.unlink()
            # END DNF
    finally:
        sys.stderr = old_stderr
        try:
            Path(dnftmp.name).unlink()
            repo = dnfbase.repos[targetid]
            cachedir = Path(repo.basecachedir) / targetid
            shutil.rmtree(cachedir)
        except Exception as ex:
            log_error("Unable to clean up: %s." % ex)
            return -1

    return retcode

def vercmp(ver1, ver2):
    # ToDo: Involve epoch?
    version, release = ver1.split("-", 1)
    first = (None, version, release)
    version, release = ver2.split("-", 1)
    second = (None, version, release)

    return rpm.labelCompare(first, second)

def clean_rawhide_repo(release):
    packages = {}
    pkgdir = Path(CONFIG["RepoDir"], release, "Packages")
    for f in pkgdir.iterdir():
        if f.suffix != ".rpm":
            continue

        pkgdata = parse_rpm_name(f.name)
        if not pkgdata["name"]:
            continue

        ver = "%s-%s" % (pkgdata["version"], pkgdata["release"])

        if not pkgdata["name"] in packages:
            packages[pkgdata["name"]] = {ver: [f.name]}
            continue

        if ver in packages[pkgdata["name"]]:
            packages[pkgdata["name"]][ver].append(f.name)
            continue

        packages[pkgdata["name"]][ver] = [f.name]

    for package in packages:
        pkgcnt = len(packages[package])
        if pkgcnt > CONFIG["KeepRawhideLatest"]:
            vers = sorted(packages[package].keys(), key=cmp_to_key(vercmp))
            i = 0
            for ver in vers:
                for filename in packages[package][ver]:
                    if i < pkgcnt - CONFIG["KeepRawhideLatest"]:
                        log_info("Removing %s" % filename)
                        (pkgdir / filename).unlink()
                i += 1

if __name__ == "__main__":
    # parse arguments
    argparser = argparse.ArgumentParser(description="Retrace Server repository downloader")
    argparser.add_argument("distribution", type=str, help="Distribution name")
    argparser.add_argument("version", type=str, help="Release version")
    argparser.add_argument("architecture", type=str, help="CPU architecture")
    argparser.add_argument("-v", "--verbose", action="count", default=0)
    args = argparser.parse_args()

    if args.verbose == 0:
        logging.basicConfig(level=logging.INFO)
    else:
        logging.basicConfig(level=logging.DEBUG)

    distribution = args.distribution
    version = args.version
    arch = get_canon_arch(args.architecture)


    if CONFIG["UseFafPackages"]:
        log_info("Creating repo from faf")
        targetid = "%s-%s-%s" % (distribution, version, arch)
        targetdir = Path(CONFIG["RepoDir"], targetid)

        if not targetdir.is_dir():
            targetdir.mkdir(parents=True)

        cmd_line = ["retrace-server-reposync-faf", distribution, version, arch,
                    "--outputdir", targetdir]
        child = run(cmd_line, stdout=PIPE, stderr=PIPE, encoding="utf-8")
        if child.returncode:
            log_error("Could not create faf repo")
            log_debug(child.stdout)
            log_debug(child.stderr)
            sys.exit(child.returncode)
        sys.exit(0)

    # drop privilegies if possible
    try:
        gr = grp.getgrnam(TARGET_GROUP)
        os.setgid(gr.gr_gid)
        pw = pwd.getpwnam(TARGET_USER)
        os.setuid(pw.pw_uid)
        log_info("Privileges set to '%s:%s'." % (TARGET_USER, TARGET_GROUP))
    except Exception as ex:
        log_error("Unable to change privileges to '%s:%s'" % (TARGET_USER, TARGET_GROUP))
        log_error(str(ex))
        sys.exit(6)

    # load plugin
    plugin = None
    for iplugin in plugins.all():
        if iplugin.distribution == distribution:
            plugin = iplugin
            break

    if not plugin:
        log_error("Unknown distribution: '%s'" % distribution)
        sys.exit(1)

    targetid = "%s-%s-%s" % (distribution, version, arch)
    lockfile = Path("/tmp/retrace-reposync-lock-%s" % targetid)

    if lockfile.is_file():
        log_error("Another process with repository download is running")
        sys.exit(2)

    # set lock
    if not lock(lockfile):
        log_error("Unable to set lock")
        sys.exit(3)

    null = None
    if args.verbose < 2:
        null = DEVNULL

    try:
        targetdir = Path(CONFIG["RepoDir"], targetid)
        pkgdir = targetdir / "Packages"

        if not pkgdir.is_dir():
            pkgdir.mkdir(parents=True)

        for filepath in targetdir.iterdir():
            if filepath.suffix == ".rpm":
                filepath.rename(pkgdir / filepath.name)

        globaldnfcfg = ""
        if hasattr(plugin, "dnfcfg"):
            globaldnfcfg = plugin.dnfcfg.replace("$ARCH", arch).replace("$VER", version)

        i = 0
        # run rsync
        for repo in plugin.repos:
            i += 1
            retcode = -1
            localdnfcfg = ""
            if isinstance(repo, tuple):
                repo, localdnfcfg = repo
                localdnfcfg = localdnfcfg.replace("$ARCH", arch).replace("$VER", version)

            for mirror in repo:
                repourl = mirror.replace("$ARCH", arch).replace("$VER", version)
                log_info("[%d / %d] Repo: %s" % (i, len(plugin.repos), repourl))
                log_info("Downloading packages")
                sys.stdout.flush()

                if repourl.startswith("http://") or \
                   repourl.startswith("https://") or \
                   repourl.startswith("ftp://"):
                    retcode = sync_using_dnf(targetid, repourl, globaldnfcfg, localdnfcfg)
                else:
                    if repourl.startswith("rsync://"):
                        files = [repourl]
                    else:
                        # folder in FS
                        files = []
                        try:
                            for package in Path(repourl).iterdir():
                                files.append(package)
                        except Exception as ex:
                            log_warn("Download failed: %s" % ex)
                            log_info("Trying another mirror")
                            continue

                    retcode = run(["rsync", "-t"] + files + [pkgdir], stdout=null, stderr=null).returncode

                if retcode == 0:
                    log_info("Download succeeded")
                    break

                log_warn("Download failed, trying another mirror")

            if retcode != 0:
                log_error("Download failed, no more mirrors to try")

        if version.lower() == "rawhide":
            log_info("Cleaning rawhide repo...")
            clean_rawhide_repo(targetid)

        # run createrepo
        log_info("Running createrepo on '%s'..." % targetdir)
        sys.stdout.flush()

        cmd = ["createrepo", targetdir]
        if CONFIG["UseCreaterepoUpdate"]:
            cmd.append("--update")

        retcode = run(cmd, stdout=null, stderr=null).returncode
    finally:
        unlock(lockfile)

    if retcode != 0:
        log_error("Failed")
        sys.exit(4)

    log_info("Repository synchronization finished successfully")
